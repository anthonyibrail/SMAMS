{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFxg3FpdfRtZ"
      },
      "source": [
        "### Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wBSXFKP3fRtd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QV1_HcP0fRte",
        "outputId": "36702834-a9cc-4788-c331-029ece9af4a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "tf.__version__ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfvI2tQ5fRtf"
      },
      "source": [
        "### Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRszar_7fRtf"
      },
      "source": [
        "#### Generating images for the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kvKUlXzJfRtf"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWGS9nU5fRtg"
      },
      "source": [
        "#### Generating images for the Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uezqq37hfRtg"
      },
      "outputs": [],
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA7k0shIfRth"
      },
      "source": [
        "### Creating the Training set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUCdaPtTfZTt",
        "outputId": "268ccdf9-2ed8-4f1e-a607-34a716714b46"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32sUs2sefRth",
        "outputId": "060b9f70-ba70-4a51-ff21-850f2922cb33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7000 images belonging to 24 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set = train_datagen.flow_from_directory('./drive/MyDrive/dataSet/trainingData',                                \n",
        "                                                 target_size = (128, 128),\n",
        "                                                 batch_size = 10,\n",
        "                                                 color_mode = 'grayscale',                                \n",
        "                                                 class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzNpPRgIfRti",
        "outputId": "dea195c2-17db-4595-d4fb-d66130547715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1727 images belonging to 24 classes.\n"
          ]
        }
      ],
      "source": [
        "test_set = test_datagen.flow_from_directory('./drive/MyDrive/dataSet/testingData',\n",
        "                                            target_size = (128, 128),                                  \n",
        "                                            batch_size = 10,        \n",
        "                                            color_mode = 'grayscale',\n",
        "                                            class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIafDyhqfRti"
      },
      "source": [
        "### Part 2 - Building the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKcEiZdtfRtj"
      },
      "source": [
        "#### Initializing the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OGK-14ExfRtj"
      },
      "outputs": [],
      "source": [
        "classifier = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eryeU2pfRtj"
      },
      "source": [
        "#### Step 1 - Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9MCtJ5nGfRtk"
      },
      "outputs": [],
      "source": [
        "classifier.add(tf.keras.layers.Conv2D(filters=32,\n",
        "                                     kernel_size=3, \n",
        "                                     padding=\"same\", \n",
        "                                     activation=\"relu\", \n",
        "                                     input_shape=[128, 128, 1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoT0F_KmfRtk"
      },
      "source": [
        "#### Step 2 - Pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "CHA9sHhpfRtk"
      },
      "outputs": [],
      "source": [
        "classifier.add(tf.keras.layers.MaxPool2D(pool_size=2, \n",
        "                                         strides=2, \n",
        "                                         padding='valid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V10Ar4-ZfRtk"
      },
      "source": [
        "#### Adding a second convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "NHJuuY6-fRtl"
      },
      "outputs": [],
      "source": [
        "classifier.add(tf.keras.layers.Conv2D(filters=32, \n",
        "                                      kernel_size=3, \n",
        "                                      padding=\"same\", \n",
        "                                      activation=\"relu\"))\n",
        "\n",
        "classifier.add(tf.keras.layers.MaxPool2D(pool_size=2, \n",
        "                                         strides=2, \n",
        "                                         padding='valid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVc8MYPLfRtl"
      },
      "source": [
        "#### Step 3 - Flattening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kxiQLUnCfRtl"
      },
      "outputs": [],
      "source": [
        "classifier.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TXQ1V9-fRtl"
      },
      "source": [
        "#### Step 4 - Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "xWZdgewnfRtl"
      },
      "outputs": [],
      "source": [
        "classifier.add(tf.keras.layers.Dense(units=128, \n",
        "                                     activation='relu'))\n",
        "classifier.add(tf.keras.layers.Dropout(0.40))\n",
        "classifier.add(tf.keras.layers.Dense(units=96, activation='relu'))\n",
        "classifier.add(tf.keras.layers.Dropout(0.40))\n",
        "classifier.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "classifier.add(tf.keras.layers.Dense(units=24, activation='softmax')) # softmax for more than 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FINSmfQ2fRtm"
      },
      "source": [
        "### Part 3 - Training the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R4D0kO5fRtm"
      },
      "source": [
        "#### Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "xKkiGTobfRtm"
      },
      "outputs": [],
      "source": [
        "classifier.compile(optimizer = 'adam', \n",
        "                   loss = 'categorical_crossentropy', \n",
        "                   metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC5i8RrnfRtm"
      },
      "source": [
        "#### Training the CNN on the Training set and evaluating it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgRfCVMQfRtm",
        "outputId": "00e8e3b2-a06a-4c12-8c08-70d765a62146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 128, 128, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 64, 64, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 32, 32, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               4194432   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 96)                12384     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 96)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                6208      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 27)                1755      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               3584      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 96)                12384     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 96)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                6208      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 24)                1560      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,248,083\n",
            "Trainable params: 4,248,083\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "classifier.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noIWtOkqfRtn",
        "outputId": "f75771a3-c2ed-4ccf-dc0a-5a0fe87183df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "700/700 [==============================] - 1828s 3s/step - loss: 3.1734 - accuracy: 0.0397 - val_loss: 3.1674 - val_accuracy: 0.0428\n",
            "Epoch 2/10\n",
            "700/700 [==============================] - 180s 257ms/step - loss: 3.1556 - accuracy: 0.0443 - val_loss: 3.0193 - val_accuracy: 0.0857\n",
            "Epoch 3/10\n",
            "700/700 [==============================] - 182s 260ms/step - loss: 2.7889 - accuracy: 0.0979 - val_loss: 2.5059 - val_accuracy: 0.1141\n",
            "Epoch 4/10\n",
            "700/700 [==============================] - 184s 262ms/step - loss: 2.5526 - accuracy: 0.1244 - val_loss: 2.4575 - val_accuracy: 0.1291\n",
            "Epoch 5/10\n",
            "700/700 [==============================] - 194s 277ms/step - loss: 2.4422 - accuracy: 0.1519 - val_loss: 2.2495 - val_accuracy: 0.1980\n",
            "Epoch 6/10\n",
            "700/700 [==============================] - 196s 280ms/step - loss: 2.3640 - accuracy: 0.1594 - val_loss: 2.2374 - val_accuracy: 0.1726\n",
            "Epoch 7/10\n",
            "700/700 [==============================] - 194s 277ms/step - loss: 2.3090 - accuracy: 0.1757 - val_loss: 2.0768 - val_accuracy: 0.2113\n",
            "Epoch 8/10\n",
            "700/700 [==============================] - 197s 281ms/step - loss: 2.2500 - accuracy: 0.1833 - val_loss: 2.2704 - val_accuracy: 0.2339\n",
            "Epoch 9/10\n",
            "700/700 [==============================] - 191s 273ms/step - loss: 2.1791 - accuracy: 0.1929 - val_loss: 2.0393 - val_accuracy: 0.2154\n",
            "Epoch 10/10\n",
            "700/700 [==============================] - 195s 278ms/step - loss: 2.1462 - accuracy: 0.2064 - val_loss: 1.9814 - val_accuracy: 0.2803\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6f34eba320>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "classifier.fit(training_set,\n",
        "                  epochs = 10,\n",
        "                  validation_data = test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw5K9DCEfRtn"
      },
      "source": [
        "#### Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86jx3iBnfRtn",
        "outputId": "bbc48015-501c-4974-972e-2839c30e5788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved\n",
            "Weights saved\n"
          ]
        }
      ],
      "source": [
        "model_json = classifier.to_json()\n",
        "with open(\"model_new_8.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "print('Model Saved')\n",
        "classifier.save_weights('model_new_8.h5')\n",
        "print('Weights saved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIoo0bX1fRtn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6rc1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}