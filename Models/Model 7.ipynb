{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFxg3FpdfRtZ"
      },
      "source": [
        "### Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wBSXFKP3fRtd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QV1_HcP0fRte",
        "outputId": "15b3cdb0-dfd8-4d85-e76b-73bc44f5a0fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "tf.__version__ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfvI2tQ5fRtf"
      },
      "source": [
        "### Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRszar_7fRtf"
      },
      "source": [
        "#### Generating images for the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kvKUlXzJfRtf"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWGS9nU5fRtg"
      },
      "source": [
        "#### Generating images for the Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uezqq37hfRtg"
      },
      "outputs": [],
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA7k0shIfRth"
      },
      "source": [
        "### Creating the Training set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUCdaPtTfZTt",
        "outputId": "67013e31-a58c-47a9-ee0d-5f67b86e0824"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32sUs2sefRth",
        "outputId": "d3806c24-4be0-4b7a-d0ae-833cf93b02aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7000 images belonging to 24 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set = train_datagen.flow_from_directory('./drive/MyDrive/dataSet/trainingData',                                \n",
        "                                                 target_size = (128, 128),\n",
        "                                                 batch_size = 10,\n",
        "                                                 color_mode = 'grayscale',                                \n",
        "                                                 class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzNpPRgIfRti",
        "outputId": "be2f4787-0cff-4947-af69-f3a3d4c6b8e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1730 images belonging to 27 classes.\n"
          ]
        }
      ],
      "source": [
        "test_set = test_datagen.flow_from_directory('./drive/MyDrive/dataSet/testingData',\n",
        "                                            target_size = (128, 128),                                  \n",
        "                                            batch_size = 10,        \n",
        "                                            color_mode = 'grayscale',\n",
        "                                            class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIafDyhqfRti"
      },
      "source": [
        "### Part 2 - Building the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKcEiZdtfRtj"
      },
      "source": [
        "#### Initializing the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OGK-14ExfRtj"
      },
      "outputs": [],
      "source": [
        "classifier = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eryeU2pfRtj"
      },
      "source": [
        "#### Step 1 - Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9MCtJ5nGfRtk"
      },
      "outputs": [],
      "source": [
        "classifier.add(tf.keras.layers.Conv2D(filters=32,\n",
        "                                     kernel_size=3, \n",
        "                                     padding=\"same\", \n",
        "                                     activation=\"relu\", \n",
        "                                     input_shape=[128, 128, 1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoT0F_KmfRtk"
      },
      "source": [
        "#### Step 2 - Pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CHA9sHhpfRtk"
      },
      "outputs": [],
      "source": [
        "classifier.add(tf.keras.layers.MaxPool2D(pool_size=2, \n",
        "                                         strides=2, \n",
        "                                         padding='valid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V10Ar4-ZfRtk"
      },
      "source": [
        "#### Adding a second convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NHJuuY6-fRtl"
      },
      "outputs": [],
      "source": [
        "classifier.add(tf.keras.layers.Conv2D(filters=32, \n",
        "                                      kernel_size=3, \n",
        "                                      padding=\"same\", \n",
        "                                      activation=\"relu\"))\n",
        "\n",
        "classifier.add(tf.keras.layers.MaxPool2D(pool_size=2, \n",
        "                                         strides=2, \n",
        "                                         padding='valid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVc8MYPLfRtl"
      },
      "source": [
        "#### Step 3 - Flattening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kxiQLUnCfRtl"
      },
      "outputs": [],
      "source": [
        "classifier.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TXQ1V9-fRtl"
      },
      "source": [
        "#### Step 4 - Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xWZdgewnfRtl"
      },
      "outputs": [],
      "source": [
        "classifier.add(tf.keras.layers.Dense(units=128, \n",
        "                                     activation='relu'))\n",
        "classifier.add(tf.keras.layers.Dropout(0.40))\n",
        "classifier.add(tf.keras.layers.Dense(units=96, activation='relu'))\n",
        "classifier.add(tf.keras.layers.Dropout(0.40))\n",
        "classifier.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "classifier.add(tf.keras.layers.Dense(units=27, activation='softmax')) # softmax for more than 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FINSmfQ2fRtm"
      },
      "source": [
        "### Part 3 - Training the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R4D0kO5fRtm"
      },
      "source": [
        "#### Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xKkiGTobfRtm"
      },
      "outputs": [],
      "source": [
        "classifier.compile(optimizer = 'adam', \n",
        "                   loss = 'categorical_crossentropy', \n",
        "                   metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC5i8RrnfRtm"
      },
      "source": [
        "#### Training the CNN on the Training set and evaluating it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgRfCVMQfRtm",
        "outputId": "46dbed4b-be81-4a32-84b7-95bb54ed75b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 128, 128, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 64, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 64, 64, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 32, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32768)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               4194432   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 96)                12384     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 96)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                6208      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 27)                1755      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,224,347\n",
            "Trainable params: 4,224,347\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "classifier.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noIWtOkqfRtn",
        "outputId": "e43f63fb-8b6e-4d2b-940a-883a02464fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "701/701 [==============================] - 2575s 4s/step - loss: 2.9626 - accuracy: 0.0980 - val_loss: 1.9753 - val_accuracy: 0.3023\n",
            "Epoch 2/15\n",
            "701/701 [==============================] - 122s 174ms/step - loss: 2.0909 - accuracy: 0.3022 - val_loss: 1.4479 - val_accuracy: 0.5046\n",
            "Epoch 3/15\n",
            "701/701 [==============================] - 122s 174ms/step - loss: 1.6832 - accuracy: 0.4377 - val_loss: 1.1594 - val_accuracy: 0.6012\n",
            "Epoch 4/15\n",
            "701/701 [==============================] - 123s 176ms/step - loss: 1.4858 - accuracy: 0.4892 - val_loss: 0.9549 - val_accuracy: 0.6705\n",
            "Epoch 5/15\n",
            "701/701 [==============================] - 120s 171ms/step - loss: 1.3414 - accuracy: 0.5368 - val_loss: 0.8776 - val_accuracy: 0.6908\n",
            "Epoch 6/15\n",
            "701/701 [==============================] - 121s 172ms/step - loss: 1.2320 - accuracy: 0.5720 - val_loss: 0.9048 - val_accuracy: 0.6867\n",
            "Epoch 7/15\n",
            "701/701 [==============================] - 121s 173ms/step - loss: 1.1618 - accuracy: 0.6033 - val_loss: 0.8440 - val_accuracy: 0.6936\n",
            "Epoch 8/15\n",
            "701/701 [==============================] - 121s 172ms/step - loss: 1.0723 - accuracy: 0.6292 - val_loss: 0.7534 - val_accuracy: 0.7457\n",
            "Epoch 9/15\n",
            "701/701 [==============================] - 122s 174ms/step - loss: 1.0103 - accuracy: 0.6529 - val_loss: 0.7036 - val_accuracy: 0.7393\n",
            "Epoch 10/15\n",
            "701/701 [==============================] - 125s 178ms/step - loss: 0.9528 - accuracy: 0.6704 - val_loss: 0.7064 - val_accuracy: 0.7462\n",
            "Epoch 11/15\n",
            "701/701 [==============================] - 124s 176ms/step - loss: 0.9288 - accuracy: 0.6733 - val_loss: 0.6815 - val_accuracy: 0.7457\n",
            "Epoch 12/15\n",
            "701/701 [==============================] - 123s 176ms/step - loss: 0.8618 - accuracy: 0.7098 - val_loss: 0.6896 - val_accuracy: 0.7468\n",
            "Epoch 13/15\n",
            "701/701 [==============================] - 124s 176ms/step - loss: 0.8420 - accuracy: 0.7091 - val_loss: 0.6706 - val_accuracy: 0.7636\n",
            "Epoch 14/15\n",
            "701/701 [==============================] - 124s 177ms/step - loss: 0.7988 - accuracy: 0.7170 - val_loss: 0.6761 - val_accuracy: 0.7682\n",
            "Epoch 15/15\n",
            "701/701 [==============================] - 123s 175ms/step - loss: 0.7883 - accuracy: 0.7340 - val_loss: 0.6363 - val_accuracy: 0.7694\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efc61bdcc70>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "classifier.fit(training_set,\n",
        "                  epochs = 15,\n",
        "                  validation_data = test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw5K9DCEfRtn"
      },
      "source": [
        "#### Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86jx3iBnfRtn",
        "outputId": "cf95a5a6-b501-472e-cb72-969ccfc65308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved\n",
            "Weights saved\n"
          ]
        }
      ],
      "source": [
        "model_json = classifier.to_json()\n",
        "with open(\"model_new_7.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "print('Model Saved')\n",
        "classifier.save_weights('model_new_7.h5')\n",
        "print('Weights saved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIoo0bX1fRtn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6rc1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}